{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data\n",
    "- 여기에서는 머신러닝 알고리즘이 학습할 수 있는 형태로 데이터를 변환(transform)하는 과정에 대해 다룹니다.\n",
    "- 주로 `scikit-learn` 패키지 내에 있는 `preprocessing` 모듈을 통해 데이터를 변환하는 방법에 대해 알아봅시다.\n",
    "- 데이터 변환에 도움을 주는 함수를 익히는 것도 중요하지만, **어떤 과정을 통해 데이터를 분석 가능한 형태로 변환**하는지 파악하는 것이 제일 중요합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rescale the data \n",
    "- Also known as **normalization**\n",
    "- 각 변수의 값을 내가 원하는 range로 변경 (예. 0과 1사이)\n",
    "- 머신러닝의 핵심인 최적화 알고리즘을 적용하는 데에 매우 유용함 (예. Gradient descent)\n",
    "- 포인트 간의 거리를 기반으로 하는 알고리즘에서는 핵심 (예. k-means clustering, k-nearest neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import example dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv('data/pima-indians-diabetes.data', names = variables)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = data.shape[0]\n",
    "num_cols = data.shape[1]\n",
    "print(num_rows)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame to Array\n",
    "- 본 방법에서는 `scikit-learn` 내 `MinMaxScaler`라는 함수를 사용할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array = data.values\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터에서 클래스는 0과 1사이로 스케일링이 될 필요가 없다.\n",
    "- 따라서 스케일이 필요한 입력변수들을 X, 클래스를 Y로 분리를 한 후 X에만 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1은 마지막 인덱스를 의미함\n",
    "# array[:, 0:-1] 은 모든 행, 첫 번째 열부터 마지막 열 직전까지의 열을 따로 분리한다는 뜻\n",
    "X = array[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = array[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.preprocessing.MinMaxScaler`\n",
    "- 참고: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledX = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "print(X[0:5,:])\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize the data \n",
    "- 각 변수의 값을 standard Gaussian distribution (with a mean of 0 and a standard deviation of 1) 를 따르도록 데이터를 바꾸는 방법\n",
    "- 입력변수가 지나치게 왜도(skewness)가 크지 않을 때에 특히 효과적\n",
    "- 몇 가지 머신러닝 알고리즘 중 입력변수의 정규성을 가정하거나 rescale이 효과적인 것에 적합함 (예. Linear regression, Logistic regression, Linear discriminant analysis 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.preprocessing.StandardScaler`\n",
    "- 참고: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "rescaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(\"[Original data]\")\n",
    "print(X[0:5, :])\n",
    "print(\"\\n[Transformed data]\")\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize each point \n",
    "- Normalizing in scikit-learn refers to rescaling each point (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra).\n",
    "- Useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as K-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.preprocessing.Normalizer`\n",
    "- 참고: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "# scaler = Normalizer().fit(X)\n",
    "# normalizedX = scaler.transform(X)\n",
    "normalizedX = scaler.fit_transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binarize features\n",
    "- Thresholding numerical features to get boolean values\n",
    "- 예제: 텍스트 분석에서 확률적 추론을 간단하게 만들기 위한 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "X = [[ 1., -1.,  2.], [ 2.,  0.,  0.], [ 0.,  1., -1.]]\n",
    "binarizer = Binarizer(threshold = 1.1)\n",
    "binarizedX = binarizer.transform(X)\n",
    "print(np.array(X))\n",
    "print(\"==============\")\n",
    "print(binarizedX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoding categorical variables\n",
    "- Categorical variable: 값이 nominal인 변수\n",
    "- 한 variable에 category가 총 C개가 존재하는 경우, 이를 C개의 binary dummy variables로 변환하여 수치형 데이터로 변환할 수 있다.\n",
    "- 이를 **1 of C coding** 또는 **one hot encoding** 라고 한다.\n",
    "- Using `sklearn.preprocessing.OneHotEncoder`\n",
    "- Using `pandas.get_dummies`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.preprocessing.OneHotEncoder`\n",
    "- 참고: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "- Category가 이미 숫자로 표현되어 있는 경우에 유리함. (예. 봄->1, 여름->2, 가을->3, 겨울->4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = np.array([[0,0,3],[1,1,0],[0,2,1],[1,0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform([[0,1,3]]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `pandas.get_dummies`\n",
    "- 참고: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "- DataFrame에서 바로 binary dummies를 생성하므로 매우 직관적임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'temperature': [29, 34, 36, 32, 30],\n",
    "       'humidity': ['mid', 'high', 'high', 'mid', 'low'],\n",
    "       'weather': ['cloudy', 'sunny', 'rainy', 'cloudy', 'sunny']}\n",
    "X = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedX = pd.get_dummies(X['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Missing value imputation\n",
    "- Missing value(결측치)는 행렬 계산 기반의 머신러닝 알고리즘의 경우에는 반드시 처리를 해주어야 한다. (예. Linear regression, Logistic regression, Support vector machine, 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.impute.SimpleImputer`\n",
    "- 참고: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "X = [[1,2],[np.nan,3],[7,6]]\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imp.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom transformers\n",
    "- 사용자 정의의 함수를 이용하여 변수를 transform하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.preprocessing.FunctionTransformer`\n",
    "- 참고: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p) # numpy.log1p(x) calculates log(1 + x)\n",
    "X = [[0, 1], [2, 3]]\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 많은 정보는...\n",
    "- `sklearn.preprocessing` 모듈에 대해 자세히 설명된 페이지: http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- 데이터 분석을 위해 거쳐야 하는 전처리 과정을 잘 숙지한 경우, googling 및 stackoverflow에서 더욱 많은 정보를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
